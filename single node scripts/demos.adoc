== DEMO 1 - Twitter Search - GemFire - HAWQ - SpringXD

Pull data from twitter, see what is trending at twitter.com first.

----
stream create --name tweet --definition "twittersearch --query='HowIBecameAFan' --outputType=application/json | flatten: transform --script=tweets-search.groovy --inputType=application/json | csv: transform --script=csv.groovy --inputType=application/json | hdfs --rollover=1K --directory=/tweet-data"
----

Set up analytic taps.
----
stream create tweetlang  --definition "tap:stream:tweet > field-value-counter --fieldName=lang" --deploy
stream create tweetcount --definition "tap:stream:tweet > aggregate-counter" --deploy
stream create hashtags --definition "tap:stream:tweet > field-value-counter --fieldName=entities.hashtags.text --name=hashtags" --deploy
----

Pull the most popular tweets into GemFire
----
stream create gemfireTap --definition "tap:stream:tweet.flatten > filter --expression=!(T(java.lang.Integer).parseInt(#jsonPath(payload,'$.retweet_count'))<1) | gemfire-json-server --useLocator=true --host=pivhdsne --port=10334 --regionName=tweet --keyExpression=payload.getField('id')" --deploy
----
Examine all the data with HAWQ.
----
CREATE external TABLE tweet_pxf(
   id VARCHAR(255), from_user VARCHAR(255), created_at VARCHAR(255), text VARCHAR(255),
   language_code VARCHAR(10), retweet_count INTEGER)
   location ('pxf://pivhdsne:50070/tweet-data/tweet-*.txt?profile=HdfsTextSimple')
  FORMAT 'CSV' LOG ERRORS INTO tweet_err SEGMENT REJECT LIMIT 1000;
----

Different queries can be run to show ANSI SQL compliance.
----
select from_user, sum(retweet_count) as total  from tweet_pxf group by from_user order by total desc limit 10 ;

select distinct from_user, retweet_count from tweet_pxf order by retweet_count desc, from_user desc;
----


GemFire Restful API
----
curl -i http://pivhdsne:7576/gemfire-api/v1/tweet?limit=100
----


----
cd spring-xd-samples/analytics-dashboard/
----
Start webserver
----
./startWebServer.sh (there is a tab in the windows group for this)
----

Browse to:
http://pivhdsne:9889/dashboard.html

----
hdfs -dfs -ls /tweet-data
----

*** DEMO 2 - Map Reduce vs HAWQ***
This demo shows solving the same problem different ways.  The customer will see a spectrum of possibilities, but if speed is most important it is clear HAWQ is the best.

Find top tax paid by postal code.

--must go to this dir
cd  /pivotal-samples/map-reduce-java/taxpaid_by_postalcode

--show off attributes about the file
hdfs dfs -cat /retail_demo/orders/orders.tsv.gz | zcat | more
hdfs dfs -cat /retail_demo/orders/orders.tsv.gz | zcat | wc -l
hdfs dfs -ls /retail_demo/orders/orders.tsv.gz

--time M/R job
time hadoop jar target/taxpaid_by_postalcode-1.0.jar com.pivotal.hadoop.PostalCodesPaidAmountTaxDriver /retail_demo/orders/orders.tsv.gz /output-mr1
hdfs dfs -cat /output-mr1/part-r-00000


--hawq external tables - show external tables
select billing_address_postal_code, sum(total_paid_amount::float8) as total, sum(total_tax_amount::float8) as tax from retail_demo.orders_pxf group by billing_address_postal_code order by total desc limit 10;


--hawq tables - show regular tables
select billing_address_postal_code, sum(total_paid_amount::float8) as total, sum(total_tax_amount::float8) as tax from retail_demo.orders_hawq group by billing_address_postal_code order by total desc limit 10;



*** DEMO 3 MadLib - Linear Regression ****

--view the data; predict house prices based on tax, bathroom and size
select * from houses;

--train the regression model
SELECT madlib.linregr_train( 'houses',
  'houses_linregr',
  'price',
  'ARRAY[1, tax, bath, size]'
);

--examine the results
\x ON
SELECT * FROM houses_linregr;
\x OFF

--Predict the price
SELECT houses.*,
madlib.linregr_predict( ARRAY[1,tax,bath,size],
  m.coef
) as predict,
price -
madlib.linregr_predict( ARRAY[1,tax,bath,size],
  m.coef
) as residual
FROM houses, houses_linregr m;

*** DEMO 4 - RMQ - GFXD - 2 Tables - DO NOT USE YET ****
--Insert directly into GXD
create table tweet (id VARCHAR(255), from_user VARCHAR(255), created_at VARCHAR(255), text VARCHAR(255), language_code VARCHAR(10), retweet_count INTEGER, retweet VARCHAR(10), PRIMARY KEY (id)) PARTITION BY PRIMARY KEY BUCKETS 5 eviction by criteria (language_code <> 'en') evict incoming hdfsstore (tweet) ;
create table hash_tag (id VARCHAR(255), tweet_id VARCHAR(255), text VARCHAR(255), language_code VARCHAR(10), PRIMARY KEY (id)) PARTITION BY COLUMN (tweet_id) colocate with (tweet) BUCKETS 5 eviction by criteria (language_code <> 'en') evict incoming hdfsstore (hash_tag) ;

--Spring XD Definitions
stream create --name twitterfeed --definition "twitterstream --filterLevel=medium | rabbit --exchange=twitter.fanout"
stream create --name tweet --definition "rabbit --queues=tweet --outputType=text/plain | transform --script=tweets-stream-delim.groovy --inputType=application/json | jdbc --columns='id, from_user, created_at, text, language_code, retweet_count, retweet'" --deploy
stream create --name hash_tag --definition "rabbit --queues=hash.tag --outputType=text/plain | transform --script=tweets-hash.groovy --inputType=application/json | splitter --expression=#jsonPath(payload,'$.hashtags.hashtag[*]') --inputType=application/json | jdbc --tableName=hash_tag --columns='id, tweet_id, text, language_code' --inputType=application/json " --deploy

--find most hashtags
select t.id, count(ht.tweet_id) as hash_tags  from  tweet as t left outer join  hash_tag ht on t.id = ht.tweet_id group by t.id order by count(ht.tweet_id) desc ;


--HAWQ Definitions
CREATE external TABLE tweet_pxf(
   id VARCHAR(255), from_user VARCHAR(255), created_at VARCHAR(255), text VARCHAR(255),
   language_code VARCHAR(10), retweet_count INTEGER, retweet VARCHAR(10))
   location ('pxf://pivhdsne:50070/tweet/APP.TWEET?PROFILE=GemFireXD&CHECKPOINT=false')
  FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');

CREATE external TABLE hash_tag_pxf(
   id VARCHAR(255), tweet_id VARCHAR(255), text VARCHAR(255),
   language_code VARCHAR(10))
   location ('pxf://pivhdsne:50070/hash_tag/APP.HASH_TAG?PROFILE=GemFireXD&CHECKPOINT=false')
  FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');

select t.id, count(ht.tweet_id) as hash_tags  from  tweet_pxf as t left outer join  hash_tag_pxf ht on t.id = ht.tweet_id group by t.id order by count(ht.tweet_id) desc ;

select t.id, count(ht.tweet_id) as hash_tags  from  tweet_pxf as t left outer join  hash_tag_pxf ht on t.id = ht.tweet_id group by t.id order by count(ht.tweet_id) desc ;
